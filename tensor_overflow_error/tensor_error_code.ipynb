{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= configure =========\n",
    "from cellpose_omni import io\n",
    "\n",
    "example_dir = '../../data/examples/'\n",
    "\n",
    "\n",
    "files = io.get_image_files(example_dir) \n",
    "files\n",
    "# ============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version: \", torch.__version__)\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"CUDA version: \", torch.version.cuda)\n",
    "print(\"Number of CUDA devices: \", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose_omni import core\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "print('>>> GPU activated? %d'%use_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose_omni import io, transforms\n",
    "from omnipose.utils import normalize99\n",
    "\n",
    "imgs = [io.imread(f) for f in files]\n",
    "\n",
    "# print some info about the images.\n",
    "for i in imgs:\n",
    "    print('Original image shape:',i.shape)\n",
    "    print('data type:',i.dtype)\n",
    "    print('data range:', i.min(),i.max())\n",
    "nimg = len(imgs)\n",
    "print('number of images:',nimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose_omni import models\n",
    "\n",
    "model = models.CellposeModel(gpu=True,\n",
    "                             model_type=\"plant_omni\",\n",
    "                             net_avg=False,\n",
    "                             dim=3,\n",
    "                             nchan=1,\n",
    "                             diam_mean=0,\n",
    "                             nclasses=3) # flow + dist + boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimg = len(imgs)\n",
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "masks_om, flows_om = [[]]*nimg,[[]]*nimg\n",
    "\n",
    "for k in range(nimg):\n",
    "    # imgs[k] = torch.from_numpy(imgs[k]).to(device) # attempt to try and fix the tensor overload bug\n",
    "    masks_om[k], flows_om[k], _ = model.eval(imgs[k],\n",
    "                                             channels=None,\n",
    "                                             rescale=None,\n",
    "                                             mask_threshold=-5,\n",
    "                                             net_avg=False,\n",
    "                                             transparency=True,\n",
    "                                             flow_threshold=0,\n",
    "                                             omni=True,\n",
    "                                             resample=False,\n",
    "                                             verbose=1,\n",
    "                                             diam_threshold=12,\n",
    "                                             cluster=False,\n",
    "                                             tile=True,\n",
    "                                             compute_masks=1,\n",
    "                                             flow_factor=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above produces the error."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
